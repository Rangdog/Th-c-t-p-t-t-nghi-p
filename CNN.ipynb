{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, LeakyReLU,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m                 labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(images), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m---> 29\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m     33\u001b[0m labels_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(labels)\n",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(data_paths)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.BMP\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     22\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, file)\n\u001b[1;32m---> 23\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     25\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mpreprocess_images\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_images\u001b[39m(img_path):\n\u001b[1;32m----> 9\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (img_width, img_height))\n\u001b[0;32m     11\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_path = \"Data\\\\SOCOFing\\\\Real\"\n",
    "img_height, img_width = 96, 96\n",
    "\n",
    "data_paths = [\n",
    "    \"Data\\\\SOCOFing\\\\Real\",\n",
    "    \"Data\\\\SOCOFing\\\\Altered\\\\Altered-Easy\"\n",
    "]\n",
    "def preprocess_images(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_dataset(data_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in data_paths:\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".BMP\"):\n",
    "                img_path = os.path.join(path, file)\n",
    "                img = preprocess_images(img_path)\n",
    "                images.append(img)\n",
    "                label = int(file.split(\"__\")[0]) - 1\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = load_dataset(data_paths)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\Th-c-t-p-t-t-nghi-p\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_images(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "    return img\n",
    "img_height, img_width = 96, 96\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), input_shape=(img_height, img_width, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(256, (3, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(600, activation='softmax')  # Lớp đầu ra cho phân loại\n",
    "    ])\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint('model.keras', save_best_only=True, monitor='val_loss', mode=\"min\")\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 10, mode=\"max\",restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(images, labels_categorical, epochs=100, batch_size=32, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "model.save_weights('fingerprint_model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('fingerprint_model_weights1.weights.h5')\n",
    "# Hàm trích xuất và lưu trữ đặc trưng\n",
    "def extract_and_save_features(model, data_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in data_paths:\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".BMP\"):\n",
    "                img_path = os.path.join(path, file)\n",
    "                img = preprocess_images(img_path)\n",
    "                images.append(img)\n",
    "                label = int(file.split(\"__\")[0]) - 1\n",
    "                labels.append(label)\n",
    "    images = np.array(images)\n",
    "    features = model.predict(images)\n",
    "    np.save('fingerprint_features_by_model_weight1.npy', features)\n",
    "    np.save('fingerprint_labels_by_model_weight1.npy', labels)\n",
    "\n",
    "dataset_path = [\"Data\\\\SOCOFing\\\\Real\"]\n",
    "extract_and_save_features(model, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Hàm thêm dấu vân tay mới\n",
    "# def add_new_fingerprint(model, new_fingerprint_path, new_label):\n",
    "#     # Tiền xử lý ảnh mới\n",
    "#     new_image = preprocess_images(new_fingerprint_path)\n",
    "#     new_image = np.expand_dims(new_image, axis=0)\n",
    "    \n",
    "#     # Trích xuất đặc trưng của ảnh mới\n",
    "#     new_feature = model.predict(new_image)\n",
    "    \n",
    "#     # Tải đặc trưng và nhãn hiện tại\n",
    "#     features = np.load('fingerprint_features.npy')\n",
    "#     labels = np.load('fingerprint_labels.npy')\n",
    "    \n",
    "#     # Thêm đặc trưng và nhãn mới vào cơ sở dữ liệu\n",
    "#     features = np.vstack([features, new_feature])\n",
    "#     labels = np.append(labels, new_label)\n",
    "    \n",
    "#     # Lưu lại cơ sở dữ liệu cập nhật\n",
    "#     np.save('fingerprint_features.npy', features)\n",
    "#     np.save('fingerprint_labels.npy', labels)\n",
    "\n",
    "# new_fingerprint_path = \"path/to/new/fingerprint.BMP\"\n",
    "# new_label = 601  # Giả sử đây là nhãn của dấu vân tay mới\n",
    "# add_new_fingerprint(model, new_fingerprint_path, new_label)\n",
    "\n",
    "# Hàm xác thực dấu vân tay\n",
    "def verify_fingerprint(fingerprint_image_path):\n",
    "    # Tiền xử lý ảnh đầu vào\n",
    "    input_image = preprocess_images(fingerprint_image_path)\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "    # Trích xuất đặc trưng\n",
    "    input_feature = model.predict(input_image).flatten()\n",
    "\n",
    "    # Tải đặc trưng và nhãn hiện tại\n",
    "    features = np.load('fingerprint_features.npy')\n",
    "    labels = np.load('fingerprint_labels.npy')\n",
    "\n",
    "    # Tính toán độ tương đồng cosine\n",
    "    similarities = cosine_similarity([input_feature], features)\n",
    "\n",
    "    # Tìm đặc trưng có độ tương đồng cao nhất\n",
    "    best_match_index = np.argmax(similarities)\n",
    "    best_match_label = labels[best_match_index]\n",
    "\n",
    "    print(\"Best match label:\", best_match_label)\n",
    "    print(\"Best match similarity:\", similarities[0][best_match_index])\n",
    "\n",
    "    # Kiểm tra ngưỡng để xác định khớp hay không\n",
    "    if similarities[0][best_match_index] > 0.85:\n",
    "        print(f\"Unlock successful! Matched label: {best_match_label}\")\n",
    "    else:\n",
    "        print(\"Unlock failed! No matching fingerprint found.\")\n",
    "\n",
    "# Ví dụ sử dụng hàm xác thực\n",
    "verify_fingerprint(\"Data\\\\SOCOFing\\\\Altered\\\\Altered-Medium\\\\3__M_Left_index_finger_CR.BMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('fingerprint_model_weights.weights.h5')\n",
    "output_shape = model.output_shape\n",
    "feature_size = output_shape[-1]\n",
    "print(feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def verify_fingerprint(fingerprint_image_path, model, features):\n",
    "    # Tiền xử lý ảnh đầu vào\n",
    "    input_image = preprocess_images(fingerprint_image_path)\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "    # Trích xuất đặc trưng\n",
    "    input_feature = model.predict(input_image).flatten()\n",
    "\n",
    "    # Tính toán độ tương đồng cosine\n",
    "    similarities = cosine_similarity([input_feature], features)\n",
    "\n",
    "    # Lấy độ tương đồng cao nhất\n",
    "    return similarities[0]\n",
    "def get_fingerprint_paths(directory):\n",
    "    \"\"\"Lấy tất cả các đường dẫn đến hình ảnh dấu vân tay trong thư mục.\"\"\"\n",
    "    fingerprints = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".BMP\"):\n",
    "            fingerprints.append(os.path.join(directory, file))  # Thêm đường dẫn đầy đủ\n",
    "    return fingerprints\n",
    "# Đường dẫn đến thư mục\n",
    "known_directory = \"Data/SOCOFing/Real\"\n",
    "unknown_directory = \"Data/SOCOFing/Altered/Altered-Medium\"\n",
    "# Lấy tất cả các dấu vân tay từ thư mục\n",
    "known_fingerprints = get_fingerprint_paths(known_directory)\n",
    "unknown_fingerprints = get_fingerprint_paths(unknown_directory)\n",
    "\n",
    "\n",
    "# Tính toán độ tương đồng cho các dấu vân tay khớp\n",
    "similarities_matched = []\n",
    "for fingerprint in known_fingerprints:\n",
    "    similarities = verify_fingerprint(fingerprint, model, features)\n",
    "    similarities_matched.extend(similarities)\n",
    "\n",
    "# Tính toán độ tương đồng cho các dấu vân tay không khớp\n",
    "similarities_unmatched = []\n",
    "for fingerprint in unknown_fingerprints:\n",
    "    similarities = verify_fingerprint(fingerprint, model, features)\n",
    "    similarities_unmatched.extend(similarities)\n",
    "\n",
    "# Vẽ biểu đồ phân bố\n",
    "plt.hist(similarities_matched, bins=50, alpha=0.5, label='Matched', color='g')\n",
    "plt.hist(similarities_unmatched, bins=50, alpha=0.5, label='Unmatched', color='r')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Cosine Similarity for Fingerprints')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra kích thước của các tệp đã lưu\n",
    "features = np.load('fingerprint_features_by_model_weight1.npy')\n",
    "labels = np.load('fingerprint_labels_by_model_weight1.npy')\n",
    "\n",
    "# In kích thước của features và labels\n",
    "print(\"Kích thước của đặc trưng:\", features.shape)\n",
    "print(\"Kích thước của nhãn:\", labels.shape)\n",
    "\n",
    "# Kiểm tra một số giá trị trong features và labels\n",
    "print(\"Một số giá trị trong đặc trưng:\", features[:5])  # In 5 đặc trưng đầu tiên\n",
    "print(\"Một số giá trị trong nhãn:\", labels[:5])        # In 5 nhãn đầu tiên\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
